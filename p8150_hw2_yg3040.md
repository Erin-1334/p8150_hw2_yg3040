p8105_hw2_yg3040
================

## Problem 1

Below we import and clean data from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with
data import, updates variable names, and selects the columns that will
be used in later parts fo this problem. We update `entry` from `yes` /
`no` to a logical variable. As part of data import, we specify that
`Route` columns 8-11 should be character for consistency with 1-7.

``` r
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations. .

``` r
distinct_stations = 
  trans_ent |> 
  select(station_name, line) |> 
  distinct()
```

*There are 465 distinct stations.*

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
distinct_stations_ada_compliant = 
trans_ent |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

*84 stations are ADA compliant.*

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
mean_entry = 
  trans_ent |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

*37.704918% of station entrances / exits without vending allow
entrance.*

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
distinct_stations_route_a = 
  trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()

distinct_stations_route_a_ada_compliant = 
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

*60 distinct stations serve the A train. Of the stations that serve the
A train, 17 are ADA compliant.*

## Problem 2

Read and clean the Mr. Trash Wheel sheet.

``` r
mr_trash_wheel = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel",
    range = "A2:N653") |> 
  janitor::clean_names() |> 
  mutate(
    sports_balls =
      round(sports_balls) |> 
      as.integer()
    )
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to both
datasets before combining.

``` r
professor_trash_wheel = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel",
    range = "A2:M120") |> 
  janitor::clean_names() |> 
  mutate(
    year = as.character(year)
    )

gwynnda_trash_wheel = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel",
    range = "A2:L262") |> 
  janitor::clean_names() |> 
  mutate(
    year = as.character(year)
    )

mr_trash_wheel = 
  mr_trash_wheel |> 
  mutate(source = "Mr. Trash Wheel")

professor_trash_wheel = 
  professor_trash_wheel |> 
  mutate(source = "Professor Trash Wheel")

gwynnda_trash_wheel = 
  gwynnda_trash_wheel |> 
  mutate(source = "Gwynnda Trash Wheel")

combined_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)

total_weight_prof =
  professor_trash_wheel |> 
  pull(weight_tons) |> 
  sum(na.rm = TRUE)
total_cigar_gwynnda_06_22 = 
  gwynnda_trash_wheel |> 
  filter(month == "June", year == 2022) |> 
  pull(cigarette_butts) |>
  sum(na.rm = TRUE)
```

*The `combined_trash_wheel` dataset of trash collected by the three
Trash Wheels—Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash
Wheel—contains 1029 observations. Each observation includes variables
such as the total weight of trash collected (in tons), the number of
cigarette butts, and the number of plastic bottles. For example, the
total weight of trash collected by Professor Trash Wheel is 246.74 tons.
In June 2022, Gwynnda Trash Wheel collected a total of 1.812^{4}
cigarette butts. The dataset is well-organized, allowing for easy
comparison across the different Trash Wheels and the amount of trash
they collect.*

## Problem 3

Import, clean, tidy, and otherwise wrangle each of these datasets.

*We notice that the `baker_name` variable in the `bakers` dataset
encodes both first name and last name. We will fix this as part of the
pipline.*

``` r
bakers = 
  read_csv("data/bakers.csv", na = c("NA","N/A", "", ".")) |> 
  janitor::clean_names() |> 
  separate(baker_name, c("baker_first_name", "baker_last_name"), sep = " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes = 
  read_csv("data/bakes.csv", na = c("NA","N/A", "", ".")) |> 
  janitor::clean_names() |> 
  rename(baker_first_name = baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results = 
  read_csv(
    "data/results.csv",
    na = c("NA","N/A", "", "."),
    skip = 2) |> 
  janitor::clean_names() |> 
  rename(baker_first_name = baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Check for completeness and correctness across datasets (e.g. by viewing
individual datasets and using `anti_join`)

``` r
anti_join(bakers, bakes, by = c("series", "baker_first_name"))
```

    ## # A tibble: 26 × 6
    ##    baker_first_name baker_last_name series baker_age baker_occupation   hometown
    ##    <chr>            <chr>            <dbl>     <dbl> <chr>              <chr>   
    ##  1 Alice            Fevronia            10        28 Geography teacher  Essex   
    ##  2 Amelia           LeBruin             10        24 Fashion designer   Halifax 
    ##  3 Antony           Amourdoux            9        30 Banker             London  
    ##  4 Briony           Williams             9        33 Full-time parent   Bristol 
    ##  5 Dan              Beasley-Harling      9        36 Full-time parent   London  
    ##  6 Dan              Chambers            10        32 Support worker     Rotherh…
    ##  7 David            Atherton            10        36 International hea… Whitby  
    ##  8 Helena           Garcia              10        40 Online project ma… Leeds   
    ##  9 Henry            Bird                10        20 Student            Durham  
    ## 10 Imelda           McCarron             9        33 Countryside recre… County …
    ## # ℹ 16 more rows

``` r
anti_join(bakes, bakers, by = c("series", "baker_first_name"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker_first_name signature_bake                    show_stopper
    ##    <dbl>   <dbl> <chr>            <chr>                             <chr>       
    ## 1      2       1 "\"Jo\""         Chocolate Orange CupcakesOrange … Chocolate a…
    ## 2      2       2 "\"Jo\""         Caramelised Onion, Gruyere and T… Raspberry a…
    ## 3      2       3 "\"Jo\""         Stromboli flavored with Mozzarel… Unknown     
    ## 4      2       4 "\"Jo\""         Lavender Biscuits                 Blueberry M…
    ## 5      2       5 "\"Jo\""         Salmon and Asparagus Pie          Apple and R…
    ## 6      2       6 "\"Jo\""         Rum and Raisin Baked Cheesecake   Limoncello …
    ## 7      2       7 "\"Jo\""         Raspberry & Strawberry Mousse Ca… Pain Aux Ra…
    ## 8      2       8 "\"Jo\""         Raspberry and Blueberry Mille Fe… Mini Victor…

``` r
anti_join(results, bakers, by = c("series", "baker_first_name"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker_first_name technical result    
    ##    <dbl>   <dbl> <chr>                <dbl> <chr>     
    ## 1      2       1 Joanne                  11 IN        
    ## 2      2       2 Joanne                  10 IN        
    ## 3      2       3 Joanne                   1 IN        
    ## 4      2       4 Joanne                   8 IN        
    ## 5      2       5 Joanne                   6 IN        
    ## 6      2       6 Joanne                   1 STAR BAKER
    ## 7      2       7 Joanne                   3 IN        
    ## 8      2       8 Joanne                   1 WINNER

``` r
anti_join(bakers, results, by = c("series", "baker_first_name"))
```

    ## # A tibble: 1 × 6
    ##   baker_first_name baker_last_name series baker_age baker_occupation hometown   
    ##   <chr>            <chr>            <dbl>     <dbl> <chr>            <chr>      
    ## 1 Jo               Wheatley             2        41 Housewife        Ongar, Ess…

``` r
anti_join(results, bakes, by = c("series", "baker_first_name")) |> 
  relocate(series, episode, baker_first_name)
```

    ## # A tibble: 258 × 5
    ##    series episode baker_first_name technical result    
    ##     <dbl>   <dbl> <chr>                <dbl> <chr>     
    ##  1      2       1 Joanne                  11 IN        
    ##  2      2       2 Joanne                  10 IN        
    ##  3      2       3 Joanne                   1 IN        
    ##  4      2       4 Joanne                   8 IN        
    ##  5      2       5 Joanne                   6 IN        
    ##  6      2       6 Joanne                   1 STAR BAKER
    ##  7      2       7 Joanne                   3 IN        
    ##  8      2       8 Joanne                   1 WINNER    
    ##  9      9       1 Antony                  12 IN        
    ## 10      9       1 Briony                   2 IN        
    ## # ℹ 248 more rows

``` r
anti_join(results, bakes, by = c("series", "episode", "baker_first_name")) |> 
  relocate(series, episode, baker_first_name)
```

    ## # A tibble: 596 × 5
    ##    series episode baker_first_name technical result
    ##     <dbl>   <dbl> <chr>                <dbl> <chr> 
    ##  1      1       2 Lea                     NA <NA>  
    ##  2      1       2 Mark                    NA <NA>  
    ##  3      1       3 Annetha                 NA <NA>  
    ##  4      1       3 Lea                     NA <NA>  
    ##  5      1       3 Louise                  NA <NA>  
    ##  6      1       3 Mark                    NA <NA>  
    ##  7      1       4 Annetha                 NA <NA>  
    ##  8      1       4 Jonathan                NA <NA>  
    ##  9      1       4 Lea                     NA <NA>  
    ## 10      1       4 Louise                  NA <NA>  
    ## # ℹ 586 more rows

``` r
anti_join(bakes, results, by = c("series", "episode", "baker_first_name"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker_first_name signature_bake                    show_stopper
    ##    <dbl>   <dbl> <chr>            <chr>                             <chr>       
    ## 1      2       1 "\"Jo\""         Chocolate Orange CupcakesOrange … Chocolate a…
    ## 2      2       2 "\"Jo\""         Caramelised Onion, Gruyere and T… Raspberry a…
    ## 3      2       3 "\"Jo\""         Stromboli flavored with Mozzarel… Unknown     
    ## 4      2       4 "\"Jo\""         Lavender Biscuits                 Blueberry M…
    ## 5      2       5 "\"Jo\""         Salmon and Asparagus Pie          Apple and R…
    ## 6      2       6 "\"Jo\""         Rum and Raisin Baked Cheesecake   Limoncello …
    ## 7      2       7 "\"Jo\""         Raspberry & Strawberry Mousse Ca… Pain Aux Ra…
    ## 8      2       8 "\"Jo\""         Raspberry and Blueberry Mille Fe… Mini Victor…

*By using `anti_join`, we notice:*

*\* The `bakes` dataset doesn’t have the records for series 9 and series
10.*

*\* Both the `bakers` and the `bakes` dataset misspell the contestant’s
name “Joanne” as “Jo”. And the `bakes` dataset has extra quotation marks
around it.*

*The second one can be fixed:*

``` r
mutate(bakers,
    baker_first_name = gsub('Jo', 'Joanne', baker_first_name)
    )
```

    ## # A tibble: 120 × 6
    ##    baker_first_name baker_last_name series baker_age baker_occupation   hometown
    ##    <chr>            <chr>            <dbl>     <dbl> <chr>              <chr>   
    ##  1 Ali              Imdad                4        25 Charity worker     Saltley…
    ##  2 Alice            Fevronia            10        28 Geography teacher  Essex   
    ##  3 Alvin            Magallanes           6        37 Nurse              Brackne…
    ##  4 Amelia           LeBruin             10        24 Fashion designer   Halifax 
    ##  5 Andrew           Smyth                7        25 Aerospace engineer Derby /…
    ##  6 Annetha          Mills                1        30 Midwife            Essex   
    ##  7 Antony           Amourdoux            9        30 Banker             London  
    ##  8 Beca             Lyne-Pirkis          4        31 Military Wives' C… Aldersh…
    ##  9 Ben              Frazer               2        31 Graphic Designer   Northam…
    ## 10 Benjamina        Ebuehi               7        23 Teaching assistant South L…
    ## # ℹ 110 more rows

``` r
mutate(bakes,
    baker_first_name = gsub('\"Jo\"', 'Joanne', baker_first_name)
    )
```

    ## # A tibble: 548 × 5
    ##    series episode baker_first_name signature_bake                   show_stopper
    ##     <dbl>   <dbl> <chr>            <chr>                            <chr>       
    ##  1      1       1 Annetha          "Light Jamaican Black Cakewith … Red, White …
    ##  2      1       1 David            "Chocolate Orange Cake"          Black Fores…
    ##  3      1       1 Edd              "Caramel Cinnamon and Banana Ca… <NA>        
    ##  4      1       1 Jasminder        "Fresh Mango and Passion Fruit … <NA>        
    ##  5      1       1 Jonathan         "Carrot Cake with Lime and Crea… Three Tiere…
    ##  6      1       1 Lea              "Cranberry and Pistachio Cakewi… Raspberries…
    ##  7      1       1 Louise           "Carrot and Orange Cake"         Never Fail …
    ##  8      1       1 Mark             "Sticky Marmalade Tea Loaf"      Heart-shape…
    ##  9      1       1 Miranda          "Triple Layered Brownie Meringu… Three Tiere…
    ## 10      1       1 Ruth             "Three Tiered Lemon Drizzle Cak… Classic Cho…
    ## # ℹ 538 more rows

Merge to create a single, final dataset; and organize this so that
variables and observations are in meaningful orders. Export the result
as a CSV in the directory containing the original datasets.

``` r
combined_df = 
  left_join(results, bakers, by = c("series", "baker_first_name")) |> 
  left_join(bakes, by = c("series", "episode", "baker_first_name")) |>   
  relocate(series, episode, baker_first_name, baker_last_name, baker_age, baker_occupation, hometown, signature_bake, show_stopper, technical, result) |> 
  arrange(series, episode)

write_csv(combined_df, "data/combined_df")
```

*The final `combined_df` dataset contains information about the bakers,
their bakes, and their performance in each episode across all 10 seasons
of the Great British Bake Off. The dataset includes variables such as
`baker_first_name`, `baker_last_name`, `signature_bake`, `show_stopper`,
`technical`, `result`, etc. It is well-organized by `series` and
`episode`, allowing for easy analysis and exploration of patterns in
baker performance.*

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10.

``` r
winner =
  results |> 
  select(series, episode, baker_first_name, result) |> 
  filter(series >= 5, series <= 10, 
         result %in% c("STAR BAKER", "WINNER")) |> 
  pivot_wider(
    names_from = series, 
    names_prefix = "series_",
    values_from = baker_first_name
    ) |> 
  relocate(episode, result)
```

*Richard in Season 5 stands out, winning “Star Baker” in five episodes,
which makes his success seem predictable. However, despite his strong
performance throughout the series, he did not win the overall
competition, which could be considered a surprise. Rahul in Season 9 won
“Star Baker” in two episodes and ultimately became the overall winner,
indicating a strong and consistent performance throughout the season.
Steph in Season 10 was named “Star Baker” in four episodes, which
suggested that she might win the competition, but the winner ended up
being David, which might be unexpected given Steph’s strong showing.
Nancy in Season 5, who won the overall competition, only won “Star
Baker” once, making her win a bit more surprising compared to Richard’s
consistent performance.*

Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?

``` r
viewers = 
  read_csv("data/viewers.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers |> 
  head(10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
average_viewership_s1 = 
  viewers |> 
  pull(series_1) |> 
  mean(na.rm = TRUE)

average_viewership_s5 = 
  viewers |> 
  pull(series_5) |> 
  mean(na.rm = TRUE)
```

*The average viewership in Season 1 is 2.77.The average viewership in
Season 5 is 10.0393.*

*Noticed the `viewers` dataset was untidy. We can tidy and reorganize
the data in `viewers` dataset. (Although the untidy data in this case is
understandable to human readers. ) Show the first 10 rows of this
dataset.*

``` r
viewers = 
  viewers |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewers"
  ) |> 
  mutate(
    series = sub("series_", "", series),
    series = as.integer(series)
  ) |> 
  arrange(series) |> 
  relocate(series)

viewers |> 
  head(10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewers
    ##     <int>   <dbl>   <dbl>
    ##  1      1       1    2.24
    ##  2      1       2    3   
    ##  3      1       3    3   
    ##  4      1       4    2.6 
    ##  5      1       5    3.03
    ##  6      1       6    2.75
    ##  7      1       7   NA   
    ##  8      1       8   NA   
    ##  9      1       9   NA   
    ## 10      1      10   NA
